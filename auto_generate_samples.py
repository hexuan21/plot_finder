#!/usr/bin/env python3
"""
è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•æ ·æœ¬ï¼šä»åŸå§‹æ•°æ®ä¸­é€‰æ‹©10éƒ¨ç”µå½±ï¼Œåˆ›å»ºqueryå¹¶è‡ªåŠ¨æ ‡æ³¨
"""

import json
import random
from pathlib import Path
from retrieval_method.bm25_retrieval import bm25_retrieval

# æ‰‹åŠ¨ç²¾é€‰çš„10éƒ¨ç”µå½±åŠå…¶æ”¹ç¼–query
SELECTED_MOVIES = [
    {
        "wiki_movie_id": "23890098",
        "query": "A taxi driver and a musician develop an unlikely friendship despite their different backgrounds and initial conflicts"
    },
    {
        "wiki_movie_id": "18737103", 
        "query": "A film director locks himself in a coffin by accident and becomes fascinated by death, eventually joining a mysterious cult"
    },
    {
        "wiki_movie_id": "15985034",
        "query": "A woman believes she will marry her seventh boyfriend, but falls in love with number six and must find a replacement"
    },
    {
        "wiki_movie_id": "34114113",
        "query": "After leaving prison, a woman searches for her unknown father among two men her mother once loved"
    },
    {
        "wiki_movie_id": "4996220",
        "query": "A mystical shopkeeper with supernatural powers breaks sacred rules when she falls in love with a customer"
    },
    {
        "wiki_movie_id": "35744959",
        "query": "God plans to destroy Sodom, but the corrupt king schemes to swap places with the righteous man meant to be saved"
    },
    {
        "wiki_movie_id": "20663735",
        "query": "A man wrongly imprisoned for murder seeks revenge on those who framed him after his release from prison"
    },
    {
        "wiki_movie_id": "8598070",
        "query": "Two skiers meet in Aspen and one follows the other across the country"
    },
    {
        "wiki_movie_id": "3797781",
        "query": "Two sisters go abroad for work, but conflict arises when one announces her pregnancy"
    },
    {
        "wiki_movie_id": "31186339",
        "query": "In a dystopian future, teenagers are forced to fight to the death in a televised competition until only one survives"
    }
]

def get_all_chunk_paths(data_dir="data"):
    """è·å–æ‰€æœ‰æ•°æ®chunkæ–‡ä»¶"""
    data_path = Path(data_dir)
    chunks = sorted(data_path.glob("all_info_chunk*.json"))
    return [str(p) for p in chunks]

def load_all_movies(chunk_paths):
    """åŠ è½½æ‰€æœ‰ç”µå½±æ•°æ®"""
    all_movies = []
    for path in chunk_paths:
        with open(path, 'r', encoding='utf-8') as f:
            movies = json.load(f)
            all_movies.extend(movies)
    return all_movies

def find_movie_by_id(movies, movie_id):
    """æ ¹æ®IDæ‰¾åˆ°ç”µå½±"""
    for movie in movies:
        if movie.get('wiki_movie_id') == movie_id:
            return movie
    return None

def auto_select_matches(results, source_id):
    """
    è‡ªåŠ¨é€‰æ‹©strongå’Œweak matches
    è§„åˆ™ï¼š
    - Strong: sourceç”µå½± + åˆ†æ•°>source*0.8çš„å‰2ä¸ª
    - Weak: åˆ†æ•°åœ¨source*0.4åˆ°source*0.8ä¹‹é—´çš„ï¼Œé€‰4-6ä¸ª
    """
    if not results:
        return [], []
    
    # æ‰¾åˆ°sourceç”µå½±çš„åˆ†æ•°
    source_score = None
    source_idx = None
    for i, r in enumerate(results):
        if r.get('wiki_movie_id') == source_id:
            source_score = r.get('_score', 0)
            source_idx = i
            break
    
    if source_score is None:
        # å¦‚æœæ‰¾ä¸åˆ°sourceï¼Œç”¨ç¬¬ä¸€ä¸ªä½œä¸ºåŸºå‡†
        source_score = results[0].get('_score', 100)
        source_idx = 0
    
    strong_matches = []
    weak_matches = []
    
    # Strong matches: åŒ…å«source + åˆ†æ•°>=source*0.6çš„å…¶ä»–ç”µå½±ï¼ˆæœ€å¤š3ä¸ªï¼‰
    for i, r in enumerate(results[:15]):  # åªçœ‹å‰15ä¸ª
        score = r.get('_score', 0)
        if r.get('wiki_movie_id') == source_id:
            strong_matches.append({
                "wiki_movie_id": r.get('wiki_movie_id'),
                "movie_name": r.get('movie_name'),
                "release_date": r.get('release_date'),
                "score": score
            })
        elif score >= source_score * 0.6 and len(strong_matches) < 3:
            strong_matches.append({
                "wiki_movie_id": r.get('wiki_movie_id'),
                "movie_name": r.get('movie_name'),
                "release_date": r.get('release_date'),
                "score": score
            })
    
    # Weak matches: åˆ†æ•°åœ¨source*0.3åˆ°source*0.6ä¹‹é—´çš„ï¼ˆ4-6ä¸ªï¼‰
    for i, r in enumerate(results[:30]):  # çœ‹å‰30ä¸ª
        score = r.get('_score', 0)
        if source_score * 0.3 <= score < source_score * 0.6 and len(weak_matches) < 6:
            if r.get('wiki_movie_id') != source_id:  # ä¸è¦é‡å¤source
                weak_matches.append({
                    "wiki_movie_id": r.get('wiki_movie_id'),
                    "movie_name": r.get('movie_name'),
                    "release_date": r.get('release_date'),
                    "score": score
                })
    
    # å¦‚æœweak matchesä¸å¤Ÿï¼Œä»ä¸­é—´åˆ†æ•°åŒºåŸŸè¡¥å……
    if len(weak_matches) < 3:
        for i, r in enumerate(results[3:20]):  # è·³è¿‡å‰3ä¸ªï¼Œçœ‹åé¢çš„
            if len(weak_matches) >= 5:
                break
            if r.get('wiki_movie_id') not in [m['wiki_movie_id'] for m in strong_matches + weak_matches]:
                weak_matches.append({
                    "wiki_movie_id": r.get('wiki_movie_id'),
                    "movie_name": r.get('movie_name'),
                    "release_date": r.get('release_date'),
                    "score": r.get('_score', 0)
                })
    
    return strong_matches, weak_matches

def generate_test_samples():
    """ç”Ÿæˆ10ä¸ªæµ‹è¯•æ ·æœ¬"""
    print("ğŸš€ å¼€å§‹è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•æ ·æœ¬...")
    
    # åŠ è½½æ‰€æœ‰æ•°æ®
    chunk_paths = get_all_chunk_paths("data")
    print(f"ğŸ“š åŠ è½½æ•°æ®æ–‡ä»¶: {len(chunk_paths)} ä¸ª")
    
    all_movies = load_all_movies(chunk_paths)
    print(f"ğŸ¬ æ€»å…±åŠ è½½ç”µå½±: {len(all_movies)} éƒ¨")
    
    new_samples = []
    
    for idx, selected in enumerate(SELECTED_MOVIES, 1):
        movie_id = selected['wiki_movie_id']
        query = selected['query']
        
        print(f"\n{'='*80}")
        print(f"[{idx}/10] å¤„ç†: {query[:60]}...")
        
        # æ‰¾åˆ°sourceç”µå½±
        source_movie = find_movie_by_id(all_movies, movie_id)
        if not source_movie:
            print(f"âš ï¸  æ‰¾ä¸åˆ°ç”µå½± {movie_id}ï¼Œè·³è¿‡")
            continue
        
        print(f"    Source: {source_movie['movie_name']} ({source_movie['release_date']})")
        
        # BM25æ£€ç´¢
        print(f"    ğŸ” BM25æ£€ç´¢ä¸­...")
        results = bm25_retrieval(
            json_path_list=chunk_paths,
            query=query,
            top_k=50,
            title_key="movie_name",
            summary_key="summary",
            return_fields=["movie_name", "release_date", "summary", "wiki_movie_id", "genres"]
        )
        
        if not results:
            print(f"    âš ï¸  æ²¡æœ‰æ£€ç´¢ç»“æœï¼Œè·³è¿‡")
            continue
        
        print(f"    âœ… æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
        
        # è‡ªåŠ¨é€‰æ‹©matches
        strong_matches, weak_matches = auto_select_matches(results, movie_id)
        
        print(f"    ğŸ“Š Strong: {len(strong_matches)} ä¸ª, Weak: {len(weak_matches)} ä¸ª")
        
        # æ„å»ºæ ·æœ¬
        sample = {
            "query": query,
            "source": {
                "wiki_movie_id": movie_id,
                "movie_name": source_movie['movie_name']
            },
            "strong_matches": strong_matches,
            "weak_matches": weak_matches
        }
        
        new_samples.append(sample)
        
        # æ˜¾ç¤ºåŒ¹é…çš„ç”µå½±
        print(f"    Strong matches:")
        for m in strong_matches[:2]:
            print(f"      - {m['movie_name']} ({m['release_date']}) [{m['score']:.2f}]")
        print(f"    Weak matches:")
        for m in weak_matches[:3]:
            print(f"      - {m['movie_name']} ({m['release_date']}) [{m['score']:.2f}]")
    
    print(f"\n{'='*80}")
    print(f"âœ… ç”Ÿæˆå®Œæˆ! å…± {len(new_samples)} ä¸ªæ ·æœ¬")
    
    return new_samples

def save_samples(new_samples, output_path="data/test_data.json"):
    """ä¿å­˜æ ·æœ¬åˆ°æ–‡ä»¶"""
    # åŠ è½½ç°æœ‰æ ·æœ¬
    existing = []
    if Path(output_path).exists():
        with open(output_path, 'r', encoding='utf-8') as f:
            existing = json.load(f)
    
    print(f"\nğŸ“ ç°æœ‰æ ·æœ¬: {len(existing)} ä¸ª")
    
    # è¿½åŠ æ–°æ ·æœ¬
    existing.extend(new_samples)
    
    # ä¿å­˜
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(existing, f, ensure_ascii=False, indent=4)
    
    print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {output_path}")
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {len(existing)} ä¸ª")

def main():
    print("="*80)
    print("è‡ªåŠ¨æµ‹è¯•æ ·æœ¬ç”Ÿæˆå™¨")
    print("="*80)
    
    # ç”Ÿæˆæ ·æœ¬
    new_samples = generate_test_samples()
    
    if not new_samples:
        print("\nâŒ æ²¡æœ‰ç”Ÿæˆä»»ä½•æ ·æœ¬")
        return
    
    # ç¡®è®¤ä¿å­˜
    print(f"\n{'='*80}")
    print("å‡†å¤‡ä¿å­˜åˆ° data/test_data.json")
    confirm = input("æ˜¯å¦ä¿å­˜? (y/n): ").strip().lower()
    
    if confirm == 'y':
        save_samples(new_samples)
        print("\nâœ… å®Œæˆ!")
    else:
        print("\nâŒ å·²å–æ¶ˆ")
        # å¯é€‰ï¼šä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        temp_path = "data/test_data_new.json"
        with open(temp_path, 'w', encoding='utf-8') as f:
            json.dump(new_samples, f, ensure_ascii=False, indent=4)
        print(f"ğŸ’¾ æ–°æ ·æœ¬å·²ä¿å­˜åˆ°: {temp_path}")

if __name__ == "__main__":
    main()

